{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Feature Generator\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired Number of Parts (Number of Feature Maps - 1 (for identity map))\n",
    "N_parts = 5\n",
    "\n",
    "# How many feature maps should be generated?\n",
    "N_Features_Search_Space_Dimension = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from Package-dump\n",
    "exec(open('init.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data_path_folder = \"/scratch/users/kratsioa/Desktop/Architopes-master_swish_random_partition/data/data/\"\n",
    "\n",
    "# Read Data\n",
    "data_path = data_path_folder+\"housing_complete.csv\"\n",
    "X = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Inputs\n",
    "X_train = X[X['is_train']==True]\n",
    "X_test = X[X['is_train']==False]\n",
    "# Load Outputs\n",
    "y_train = X_train['median_house_value']\n",
    "y_test = X_test['median_house_value']\n",
    "# Remove Columns Label Columns\n",
    "del X_train['is_train']\n",
    "del X_test['is_train']\n",
    "del X_train['median_house_value']\n",
    "del X_test['median_house_value']\n",
    "# Remember Column Names\n",
    "X_colnames = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Compositer\n",
    "def compositer_univariate(x):\n",
    "    # Apply Activation\n",
    "    x_out = 1 / (1 + np.math.exp(-x)) \n",
    "    # Output\n",
    "    return x_out\n",
    "\n",
    "# Vectorize\n",
    "compositer = np.vectorize(compositer_univariate)\n",
    "\n",
    "def activ_univariate(x):\n",
    "    if x<0:\n",
    "        x_out = 0.9*np.sign(x)*np.math.pow(-x,2)\n",
    "    else:\n",
    "        x_out = 0.1*np.math.pow(x,2)\n",
    "    return x_out\n",
    "\n",
    "# Vectorize\n",
    "activ = np.vectorize(activ_univariate)\n",
    "\n",
    "def activ_univariate_inv(x):\n",
    "    if x<0:\n",
    "        x_out = (1/0.9)*np.sign(x)*np.sqrt(-x)\n",
    "    else:\n",
    "        x_out = (1/0.1)*np.sqrt(x)\n",
    "    return x_out\n",
    "\n",
    "# Vectorize\n",
    "compositer = np.vectorize(activ_univariate_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implied Hyper-parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 1 part because of the identity map!\n",
    "N_parts = max(1,N_parts)\n",
    "\n",
    "# Ensure that there are at-least as many random feature maps generated as there are parts to the partition!\n",
    "N_Features_Search_Space_Dimension = max(N_parts,N_Features_Search_Space_Dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Random Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Base \"Shallow\" Prediction (Identity Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Regressor\n",
    "Loop_Regressor = LinearRegression()\n",
    "Loop_Regressor.fit(X_train,y_train)\n",
    "\n",
    "# Fit Regressor\n",
    "feature_predictions = np.array(np.abs(Loop_Regressor.predict(X_train)-y_train))\n",
    "feature_predictions = feature_predictions.reshape(feature_predictions.shape[0],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize Parameters\n",
    "#------------------------#\n",
    "# Initialize History\n",
    "past_val = -1\n",
    "current_position = 0\n",
    "# Initalize Features\n",
    "X_train_features = X_train\n",
    "X_test_features = X_test\n",
    "\n",
    "# Construct Deep Randomized Features\n",
    "#------------------------------------#\n",
    "# Set Seed\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builds \"Deep\" Features\n",
    "*Note:* We always force the identity to be a potentially valid representation.  Therefore, it is not score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FG-Progress:0.0\n",
      "FG-Progress:0.005\n",
      "FG-Progress:0.01\n",
      "FG-Progress:0.015\n",
      "FG-Progress:0.02\n",
      "FG-Progress:0.025\n",
      "FG-Progress:0.03\n",
      "FG-Progress:0.035\n",
      "FG-Progress:0.04\n",
      "FG-Progress:0.045\n",
      "FG-Progress:0.05\n",
      "FG-Progress:0.055\n",
      "FG-Progress:0.06\n",
      "FG-Progress:0.065\n",
      "FG-Progress:0.07\n",
      "FG-Progress:0.075\n",
      "FG-Progress:0.08\n",
      "FG-Progress:0.085\n",
      "FG-Progress:0.09\n",
      "FG-Progress:0.095\n",
      "FG-Progress:0.1\n",
      "FG-Progress:0.105\n",
      "FG-Progress:0.11\n",
      "FG-Progress:0.115\n",
      "FG-Progress:0.12\n",
      "FG-Progress:0.125\n",
      "FG-Progress:0.13\n",
      "FG-Progress:0.135\n",
      "FG-Progress:0.14\n",
      "FG-Progress:0.145\n",
      "FG-Progress:0.15\n",
      "FG-Progress:0.155\n",
      "FG-Progress:0.16\n",
      "FG-Progress:0.165\n",
      "FG-Progress:0.17\n",
      "FG-Progress:0.175\n",
      "FG-Progress:0.18\n",
      "FG-Progress:0.185\n",
      "FG-Progress:0.19\n",
      "FG-Progress:0.195\n",
      "FG-Progress:0.2\n",
      "FG-Progress:0.205\n",
      "FG-Progress:0.21\n",
      "FG-Progress:0.215\n",
      "FG-Progress:0.22\n",
      "FG-Progress:0.225\n",
      "FG-Progress:0.23\n",
      "FG-Progress:0.235\n",
      "FG-Progress:0.24\n",
      "FG-Progress:0.245\n",
      "FG-Progress:0.25\n",
      "FG-Progress:0.255\n",
      "FG-Progress:0.26\n",
      "FG-Progress:0.265\n",
      "FG-Progress:0.27\n",
      "FG-Progress:0.275\n",
      "FG-Progress:0.28\n",
      "FG-Progress:0.285\n",
      "FG-Progress:0.29\n",
      "FG-Progress:0.295\n",
      "FG-Progress:0.3\n",
      "FG-Progress:0.305\n",
      "FG-Progress:0.31\n",
      "FG-Progress:0.315\n",
      "FG-Progress:0.32\n",
      "FG-Progress:0.325\n",
      "FG-Progress:0.33\n",
      "FG-Progress:0.335\n",
      "FG-Progress:0.34\n",
      "FG-Progress:0.345\n",
      "FG-Progress:0.35\n",
      "FG-Progress:0.355\n",
      "FG-Progress:0.36\n",
      "FG-Progress:0.365\n",
      "FG-Progress:0.37\n",
      "FG-Progress:0.375\n",
      "FG-Progress:0.38\n",
      "FG-Progress:0.385\n",
      "FG-Progress:0.39\n",
      "FG-Progress:0.395\n",
      "FG-Progress:0.4\n",
      "FG-Progress:0.405\n",
      "FG-Progress:0.41\n",
      "FG-Progress:0.415\n",
      "FG-Progress:0.42\n",
      "FG-Progress:0.425\n",
      "FG-Progress:0.43\n",
      "FG-Progress:0.435\n",
      "FG-Progress:0.44\n",
      "FG-Progress:0.445\n",
      "FG-Progress:0.45\n",
      "FG-Progress:0.455\n",
      "FG-Progress:0.46\n",
      "FG-Progress:0.465\n",
      "FG-Progress:0.47\n",
      "FG-Progress:0.475\n",
      "FG-Progress:0.48\n",
      "FG-Progress:0.485\n",
      "FG-Progress:0.49\n",
      "FG-Progress:0.495\n",
      "FG-Progress:0.5\n",
      "FG-Progress:0.505\n",
      "FG-Progress:0.51\n",
      "FG-Progress:0.515\n",
      "FG-Progress:0.52\n",
      "FG-Progress:0.525\n",
      "FG-Progress:0.53\n",
      "FG-Progress:0.535\n",
      "FG-Progress:0.54\n",
      "FG-Progress:0.545\n",
      "FG-Progress:0.55\n",
      "FG-Progress:0.555\n",
      "FG-Progress:0.56\n",
      "FG-Progress:0.565\n",
      "FG-Progress:0.57\n",
      "FG-Progress:0.575\n",
      "FG-Progress:0.58\n",
      "FG-Progress:0.585\n",
      "FG-Progress:0.59\n",
      "FG-Progress:0.595\n",
      "FG-Progress:0.6\n",
      "FG-Progress:0.605\n",
      "FG-Progress:0.61\n",
      "FG-Progress:0.615\n",
      "FG-Progress:0.62\n",
      "FG-Progress:0.625\n",
      "FG-Progress:0.63\n",
      "FG-Progress:0.635\n",
      "FG-Progress:0.64\n",
      "FG-Progress:0.645\n",
      "FG-Progress:0.65\n",
      "FG-Progress:0.655\n",
      "FG-Progress:0.66\n",
      "FG-Progress:0.665\n",
      "FG-Progress:0.67\n",
      "FG-Progress:0.675\n",
      "FG-Progress:0.68\n",
      "FG-Progress:0.685\n",
      "FG-Progress:0.69\n",
      "FG-Progress:0.695\n",
      "FG-Progress:0.7\n",
      "FG-Progress:0.705\n",
      "FG-Progress:0.71\n",
      "FG-Progress:0.715\n",
      "FG-Progress:0.72\n",
      "FG-Progress:0.725\n",
      "FG-Progress:0.73\n",
      "FG-Progress:0.735\n",
      "FG-Progress:0.74\n",
      "FG-Progress:0.745\n",
      "FG-Progress:0.75\n",
      "FG-Progress:0.755\n",
      "FG-Progress:0.76\n",
      "FG-Progress:0.765\n",
      "FG-Progress:0.77\n",
      "FG-Progress:0.775\n",
      "FG-Progress:0.78\n",
      "FG-Progress:0.785\n",
      "FG-Progress:0.79\n",
      "FG-Progress:0.795\n",
      "FG-Progress:0.8\n",
      "FG-Progress:0.805\n",
      "FG-Progress:0.81\n",
      "FG-Progress:0.815\n",
      "FG-Progress:0.82\n",
      "FG-Progress:0.825\n",
      "FG-Progress:0.83\n",
      "FG-Progress:0.835\n",
      "FG-Progress:0.84\n",
      "FG-Progress:0.845\n",
      "FG-Progress:0.85\n",
      "FG-Progress:0.855\n",
      "FG-Progress:0.86\n",
      "FG-Progress:0.865\n",
      "FG-Progress:0.87\n",
      "FG-Progress:0.875\n",
      "FG-Progress:0.88\n",
      "FG-Progress:0.885\n",
      "FG-Progress:0.89\n",
      "FG-Progress:0.895\n",
      "FG-Progress:0.9\n",
      "FG-Progress:0.905\n",
      "FG-Progress:0.91\n",
      "FG-Progress:0.915\n",
      "FG-Progress:0.92\n",
      "FG-Progress:0.925\n",
      "FG-Progress:0.93\n",
      "FG-Progress:0.935\n",
      "FG-Progress:0.94\n",
      "FG-Progress:0.945\n",
      "FG-Progress:0.95\n",
      "FG-Progress:0.955\n",
      "FG-Progress:0.96\n",
      "FG-Progress:0.965\n",
      "FG-Progress:0.97\n",
      "FG-Progress:0.975\n",
      "FG-Progress:0.98\n",
      "FG-Progress:0.985\n",
      "FG-Progress:0.99\n",
      "FG-Progress:0.995\n",
      "Feature Generation (Learning Phase): Score Generated\n",
      "[3 6 2 5 4]\n"
     ]
    }
   ],
   "source": [
    "if N_Features_Search_Space_Dimension>0:\n",
    "    for i in range(N_Features_Search_Space_Dimension):    \n",
    "        # Transformations\n",
    "        #-----------------#\n",
    "        # Generate Random Weights and Biases\n",
    "        Weights_random = (np.random.binomial(1,.5,(X_train_features.shape[1],X_train_features.shape[1])) - .5)*2\n",
    "        biases_random = (np.random.binomial(1,.5,X_train_features.shape[1]) -.5)*2         \n",
    "        \n",
    "        # Write Non-Liearly Transformed Features only if transformation has been applied, only if Depth >0\n",
    "        # Apply Activation\n",
    "        X_train_features = compositer(X_train_features)\n",
    "        X_test_features = compositer(X_test_features)\n",
    "        # Apply Random Weights\n",
    "        X_train_features = np.matmul(X_train_features,Weights_random)\n",
    "        X_test_features = np.matmul(X_test_features,Weights_random)\n",
    "        # # Apply Bias        \n",
    "        X_train_features = X_train_features + biases_random\n",
    "        X_test_features = X_test_features + biases_random\n",
    "\n",
    "\n",
    "        # Register Best Scores\n",
    "        #----------------------#\n",
    "        # Make Predictions \n",
    "        Loop_Regressor = LinearRegression()\n",
    "        Loop_Regressor.fit(X_train,y_train)\n",
    "        # Evaluate Errors\n",
    "        loop_prediction_errors = np.array(np.abs(Loop_Regressor.predict(X_train_features)-y_train))\n",
    "        loop_prediction_errors = loop_prediction_errors.reshape(loop_prediction_errors.shape[0],1)\n",
    "        feature_predictions = np.append(feature_predictions,loop_prediction_errors,axis=1)\n",
    "        # Register Score\n",
    "        score_loop = np.mean(feature_predictions)\n",
    "        if(i == 0):\n",
    "            # Initialize Score\n",
    "            score = score_loop\n",
    "        else:\n",
    "            # Update Score\n",
    "            score = np.append(score,score_loop)\n",
    "        \n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('FG-Progress:' + str(i/N_Features_Search_Space_Dimension))\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "\n",
    "# Determined Best Features\n",
    "#--------------------------#\n",
    "best_features = np.argsort(score)[0:N_parts]\n",
    "print(best_features)\n",
    "\n",
    "# Generate Partition Training Tarets #\n",
    "#------------------------------------#\n",
    "# Extract Only the Relevant Best Predictions\n",
    "partition_labels_training = feature_predictions[:,best_features]\n",
    "partition_labels_training = np.argmin(partition_labels_training, axis=1)\n",
    "\n",
    "# Reset Seed\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best 6 features, indexed in order, are: [3 6 2 5 4]... Out of: 200 generated in total!\n"
     ]
    }
   ],
   "source": [
    "# Update User\n",
    "print(\"The best \" + str((N_parts + 1)) + \" features, indexed in order, are: \" + str(best_features) + \"... Out of: \" + str(N_Features_Search_Space_Dimension)+ \" generated in total!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_Features_Search_Space_Dimension>0:\n",
    "    for i in range(min(N_Features_Search_Space_Dimension,max(best_features))): # don't run everything if maximum is attained before iteration limit!\n",
    "        # Transformations\n",
    "        #-----------------#\n",
    "        # Generate Random Weights and Biases\n",
    "        Weights_random = (np.random.binomial(1,.5,(X_train_features.shape[1],X_train_features.shape[1])) - .5)*2\n",
    "        biases_random = (np.random.binomial(1,.5,X_train_features.shape[1]) -.5)*2         \n",
    "        \n",
    "        # Write Non-Liearly Transformed Features only if transformation has been applied, only if Depth >0\n",
    "        # Apply Activation\n",
    "        X_train_features = compositer(X_train_features)\n",
    "        X_test_features = compositer(X_test_features)\n",
    "        # Apply Random Weights\n",
    "        X_train_features = np.matmul(X_train_features,Weights_random)\n",
    "        X_test_features = np.matmul(X_test_features,Weights_random)\n",
    "        # # Apply Bias        \n",
    "        X_train_features = X_train_features + biases_random\n",
    "        X_test_features = X_test_features + biases_random\n",
    "\n",
    "\n",
    "        # Register Best Scores\n",
    "        #----------------------#\n",
    "        Loop_Regressor = LinearRegression()\n",
    "        Loop_Regressor.fit(X_train,y_train)\n",
    "        if i in best_features:\n",
    "            # Generate Array of Features to Write\n",
    "            X_Features_to_write_train = pd.DataFrame(X_train_features,columns=X_colnames).join(y_train).assign(is_train=True)\n",
    "            X_Features_to_write_test = pd.DataFrame(X_test_features,columns=X_colnames).join(y_test).assign(is_train=False)\n",
    "            X_Features_to_write = X_Features_to_write_train.append(X_Features_to_write_test, ignore_index=True)\n",
    "            # Write Features\n",
    "            \n",
    "        # Update User #\n",
    "        #-------------#\n",
    "        print('FG-Progress:' + str(i/N_Features_Search_Space_Dimension))\n",
    "\n",
    "# Update User\n",
    "#-------------#\n",
    "print('Feature Generation (Learning Phase): Score Generated')\n",
    "\n",
    "# Determined Best Features\n",
    "#--------------------------#\n",
    "best_features = np.argsort(score)[0:N_parts]\n",
    "print(best_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
